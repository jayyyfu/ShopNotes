# 探店笔记

## 亮点
1. Kafka实现异步创建订单并测试；
2. 热点数据预测及定时载入缓存；
3. ElasticSearch实现关键字搜索；
4. ...


## 项目介绍

### TODO 1. 整体架构介绍：

### 2. 部分实现思路

#### ①如何缓存热门商户信息？

1. 活动前手动缓存
  
2. （针对活动商品/商户）定时自动缓存：Spring Scheduled（分布式系统不合适：重复执行）分布式调度框架xxl-job
  
3. （针对无法提前预知的热点数据）：滑动窗口结合AOP注解实现数据请求频率记录
  


#### ②你是如何解决缓存穿透、缓存击穿、缓存雪崩的？

###### 缓存穿透

**缓存穿透的概念**

每一次查询的 key 都不在 redis 中，数据库中也没有。

一般都是属于非法的请求，比如 id<=0，比如可以在 API 入口做一些参数校验。

大量访问不存在的 key，严重影响系统的性能。

**两种解决方案:**

第一种 查询不存在的数据时，第一次查 db，没有查到结果直接返回 value 为 null，将这个 key 记录到 redis 中去。

使用空对象解决缓存击穿，但是如果数据库中新增了该空对象，也就是不是空对象了，这个时候怎么办呢？

1.value 为 null 的 key 设定一个过期时间比如 30s，如果这个请求在过期时间之后进来那么就没事。

2.在添加请求的时候，更新缓存的内容。

第二种 构建一个布隆过滤器，记录全量数据.

布隆过滤器也是重点内容,借助位图的数据结构,设计的很巧妙.

布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。

这个地方也可以引导面试官深挖布隆过滤器的内容，比如布隆过滤器的误判等情况。

**TODO 如果我先访问这个数据，放入到了布隆过滤器中，后面又删除了这个数据，在访问不就误判了吗？**

###### 缓存击穿

业务中通常有一些数据会被频繁的访问，比如秒杀活动，秒杀的商品信息，这个肯定要存在 Redis 中的，被频繁访问的数据被称为热点数据，如果缓存中这个数据过期了，大量的请求直接到数据库中，那么数据库就很容易被请求冲垮掉，这就是缓存击穿存在的问题。

对于一些很热的数据，在服务的启动的时候就写入到缓存中去，避免在高并发的首次访问数据到值数据库被击穿。

一些热点数据可以设置永不过期，一直有效。

###### 缓存雪崩

大量的存储数据同时过期了，用户的请求全部打到 mysql 上面去了。或者 Redis 故障宕机的时候，请求同样都是打到 Redis 上面。

对用缓存雪崩的解决方案：

1. 设置均匀的过期时间，避免将大量的数据设置成同一个过期时间，设置缓存数据过期的时候给数据加上一个随机数，保证数据不会在同一个时间过期。

2 互斥锁：如果发现访问的数据不在 redis 中，加一个互斥锁，保证同一时间内只有一个请求构建缓存。当缓存构建完成之后在释放锁，对于未能获取锁的请求，设置等待锁释放后重新读取缓存,要么就返回空值或者默认值。

3.让缓存一直有效，业务线程不在更新缓存，也不设置有效期，而是将缓存的更新工作交给后台线程定时更新。

业务线程不负责更新缓存，缓存也不设置过期时间，让缓存永久有效,将缓存的更新工作交给后台线程定时更新。

业务线程发现缓存消息失效后，通过消息队列发送一条消息通知后台进程更新缓存，后台线程接收消息进行更新缓存。

#### ③你是如何用乐观锁解决超卖的？

实现思路：后端收到下单请求后，先查询数据库库存是否足够，然后在扣减库存时将库存大于购买数量作为where语句中的条件，如果库存符合则扣减库存成功，如果库存不符合下单失败，返回库存不足的错误信息。

1. 为什么使用乐观锁？

商城购物场景中大多数的业务其实并不是秒杀限购类物品，而是普通的购物，如果每一个商品的下单过程都使用分布式锁来走业务流程会造成很多的性能开销，为了提高性能，对于普通类商品是不是可以使用乐观锁来走进行下单流程呢，乐观锁是假设每一次读取数据时都不会有冲突，在实际的业务场景中，普通类商品确实如此，很少会有冲突，符合乐观锁的预设，因此想要考虑对普通商品使用乐观锁来提高性能。

2. 乐观锁可以用于分布式环境吗，在分布式环境下会导致超卖吗？在分布式环境下有什么问题？

首先需要确保数据库实例只有一个，乐观锁可以用于分布式环境，不会导致库存超卖，但是在分布式环境下可能会导致限购功能失效。乐观锁在扣减库存的同时需要检查版本号的情况，如果版本号不符合预期则会扣减失败，且所有的服务器其实看到的是同一份数据库的数据，因此可以在分布式环境中使用。

3. 乐观锁可以优化掉版本号吗？

可以，这也正是黑马提供的乐观锁的实现方式。如果使用版本号，也就是每次更新库存的时候就会更新其中的版本号，然后下一次扣减库存时要保证版本号符合预期才会执行库存扣减。那么在不修改表结构的情况下，可以直接将库存信息当成版本号来使用即可。思路为：第一次对库存进行查询判断库存是否充足，扣减库存的同时检查库存是否大于需要扣减的数量，如果大于直接扣减即可。

4. 为什么要优化掉版本号，有什么优势吗？

在数据库设计的时候，不可能因为代码实现上的原因，在用户中增加一个版本号的内容，这会给数据库的设计带来巨大麻烦，而库存信息放在表中是很合理的，因此合理利用库存信息作为版本号可以合理利用数据库现有信息，后续如果需要切换业务逻辑也不需要对数据库进行更改。

5. 扣减库存的sql语句 update tb_limit_voucherwhere id = ? and stock >= buyNumberset stock = stock - buyNumber

这里的条件判断为什么要使用`stock >= buyNumber`，而不是stock = 查询到的库存呢？

从性能角度考虑，如果此时有10个并发同一时间下单，如果使用stock >= buyNumber，在库存充足的情况下，这10个并发都能够下单成功，请求数据库的次数为查询10次和更新10次，如果使用stock = 查询到的库存，那么第一次查询将会有10个查询，只有一个下单成功，但是由于库存是充足的，所以不应该给用户返回下单失败，而是继续尝试下单，第二次将会有9个并发一起查询，但是仍然只有一个请求可以下单成功，然后以此类推。在并发相同的情况下，如果使用stock = 查询到的库存作为判断条件，在极端情况下可能会导致过多不必要的查询。（例如上述例子中查询数据库的次数为10+9+8+7+6+5+4+3+2+1，数量级为$$O(n^2$$，更新次数同理）

#### ④你是如何用分布式锁解决秒杀场景下超卖的？

**分布式锁的实现细节**

1. 利用redis的string数据结构实现分布式锁

主要思路为，在Redis中存放一个锁，key中包含优惠券id，value是当前线程标识的string数据，在下单之前必须要获取这个锁才可以操作数据库，否则必须等待。在实现分布式锁时要注意加锁和释放锁的原子性。①使用redis的`setnx`方法进行加锁，同时增加过期时间，防止死锁，此方法可以保证加锁和设置过期时间这两个操作具有原子性。②在释放锁时使用Lua脚本保证校验锁属于当前线程和删除锁这两个操作具有原子性，防止误删其他线程的锁。

2. 利用redisson实现分布式锁

思路与上述基本一致，但是以上手动实现的锁不具有可重入和自动续期的功能。

可重入锁实现思路：使用hash结构来存储锁，其中hash结构的key表示这把锁是否存在，field表示当前这把锁被哪个线程持有，value表示重入次数

watchdog机制：再开启一个线程去检查业务是否完成，如果未完成，每过10s就进行一次续约，续约时间为30s

优点：解决了分布式情况下乐观锁无法实现限购功能的问题

缺点：分布式锁的实现较为复杂，性能、效率较为低下

#### ⑤你是如何使用Kafka +线程池异步创建订单的？

具体流程为，用户发起秒杀请求后，后端服务器直接提交给redis，redis根据缓存中的订单和商品信息判断购买资格，然后直接返回结果给后端服务器，如果购买成功，需要在redis中进行库存的预减，最后将下单是否成功的信息返回给服务器，服务器拿到信息后将下单业务放入Kafka消息队列后，将订单号返回给用户。而真正创建订单的是消息队列的消费者。

**问题：如果kafka挂了怎么办？**

可以做一个兜底方案，在用户下单成功之后，将订单信息保存到服务器的缓存中。如果kafka挂了，先保证服务器缓存中保存的订单号信息已经全部写入数据库中，然后将Kafka相关的业务流程停掉，相当于创建订单过程不再是异步操作。

优点：减少数据库查询次数，提高了性能；使用消息队列，解耦业务功能

缺点：缓存商品信息，增加了redis的内存占用，实现更加复杂，成本更高

**问题：异步下单时候，并发量过大，消息队列消息堆积怎么办？**

1. 生产速度大于消费速度，这样可以适当增加分区，增加consumer数量，提升消费TPS；
  
2. consumer消费性能低，查一下是否有很重的消费逻辑（比如拿到消息后写HDFS或HBASE这种逻辑就挺重的），看看是否可以优化consumer TPS；
  
3. 确保consumer端没有因为异常而导致消费阻塞;
  
4. 如果使用的是消费者组，确保没有频繁地发生rebalance。
  

**问题：补充秒杀优惠券库存，数据库和Redis中的数据是怎么处理的？**

给redis添加库存可以使用lua脚本进行添加，给mysql添加库存仍然使用锁的思想进行添加，添加库存和扣减库存的本质基本是一直的，都属于库存的更新，需要保证一致性。这里同样需要注意的问题就是如何保证两次的库存更新操作同时成功或者同时失败，可以使用分布式事务（如Seata）来确保一致性。大致思想为：向所有参与者发送准备请求，所有参与者执行操作但不提交，返回准备好的状态，如果所有参与者都返回准备好的状态，则向所有参与者发送提交请求，如果有任何一个参与者返回失败状态，则向所有参与者发送回滚请求。

**问题：如果先返回用户订单号，那如果订单信息还未消费，那么用户看到了订单号是不是不合理呢？**

用户看到了还没有写入数据库中的订单是否不合理呢？个人觉得并没有不合理，这是一种为了提高性能的做法，前面我们在向用户返回成功之前就已经向kafka发送了消息，后面只要保证在消息队列中，这个订单不会丢失，那也就保证了这个订单一定会写入数据库，当然这个保证是由kafka来完成的。

会不会存在一种情况，用户看到下单成功，但是后端由于某些不可预测的原因导致该订单最终下单失败？这里我们考虑两种情况，分别为订单消失和购买失败。订单会消失吗？不会。由于kafka中保存了信息，根据kafka的特性，订单不会消失。会由于某些原因导致购买失败吗？或许会有这种可能吧，毕竟后端太复杂了，各种情况都会有，但是我目前想不到一条合理的导致购买失败的特例。

补充一种tb pdd下单成功后，由于限购原因直接关闭订单的例子，我直接贴上截图来证明，这个做法也是tb、pdd惯用手段，我觉得面试的时候如果真的问到了这一层，可以用这个例子来说明最终的兜底方案


#### TODO ⑤你是如何使用 ElasticSearch 实现文章关键字搜索的？
